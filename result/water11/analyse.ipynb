{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127cdba9",
   "metadata": {},
   "source": [
    "# Benchmark Verifiable ABE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703906b",
   "metadata": {},
   "source": [
    "### Import Packages and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c212f7d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib pandas seaborn scikit-learn numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfffd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for publication-quality plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the data\n",
    "df = pd.read_csv('benchmark_results.csv')\n",
    "\n",
    "# Remove testing columns as requested\n",
    "df = df.drop(['MatchingSuccess', 'NonMatchingSuccess'], axis=1)\n",
    "\n",
    "print(\"VABE (Verifiable Attribute-Based Encryption) Benchmark Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Policy complexity range: {df['Size'].min()} - {df['Size'].max()} attributes\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Convert time columns to seconds for analysis\n",
    "time_columns = ['KeyGenTime(ms)', 'VerifyKeyTime(ms)', 'EncryptTime(ms)',\n",
    "                'VerifyCiphertextTime(ms)', 'DecryptMatchingTime(ms)', 'DecryptNonMatchingTime(ms)']\n",
    "\n",
    "for col in time_columns:\n",
    "    df[col.replace('(ms)', '(s)')] = df[col] / 1000\n",
    "    \n",
    "print(\"\\nBasic Statistics (milliseconds):\")\n",
    "print(df[time_columns].describe())\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451781ec",
   "metadata": {},
   "source": [
    "### Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67413ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VABE VERIFICATION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Algorithmic Complexity Analysis\n",
    "def analyze_complexity(x, y, operation_name):\n",
    "    \"\"\"Analyze time complexity by fitting different models\"\"\"\n",
    "    print(f\"\\n{operation_name} Complexity Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Linear fit O(n)\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(x.reshape(-1, 1), y)\n",
    "    linear_pred = linear_model.predict(x.reshape(-1, 1))\n",
    "    linear_r2 = r2_score(y, linear_pred)\n",
    "    linear_coef = linear_model.coef_[0]\n",
    "\n",
    "    # Quadratic fit O(n²)\n",
    "    poly_features = PolynomialFeatures(degree=2)\n",
    "    x_poly = poly_features.fit_transform(x.reshape(-1, 1))\n",
    "    quad_model = LinearRegression()\n",
    "    quad_model.fit(x_poly, y)\n",
    "    quad_pred = quad_model.predict(x_poly)\n",
    "    quad_r2 = r2_score(y, quad_pred)\n",
    "\n",
    "    # Log-linear fit O(n log n)\n",
    "    log_x = np.log(x)\n",
    "    log_model = LinearRegression()\n",
    "    log_model.fit(log_x.reshape(-1, 1), y)\n",
    "    log_pred = log_model.predict(log_x.reshape(-1, 1))\n",
    "    log_r2 = r2_score(y, log_pred)\n",
    "\n",
    "    # Power law fit for complexity estimation\n",
    "    log_x_vals = np.log(x)\n",
    "    log_y_vals = np.log(y)\n",
    "    power_slope, power_intercept, power_r, _, _ = stats.linregress(log_x_vals, log_y_vals)\n",
    "\n",
    "    print(f\"Linear O(n):        R² = {linear_r2:.4f}, Slope = {linear_coef:.6f}\")\n",
    "    print(f\"Quadratic O(n²):    R² = {quad_r2:.4f}\")\n",
    "    print(f\"Log-linear O(n log n): R² = {log_r2:.4f}\")\n",
    "    print(f\"Power law O(n^{power_slope:.2f}): R² = {power_r**2:.4f}\")\n",
    "\n",
    "    # Determine complexity class\n",
    "    if power_slope < 1.2:\n",
    "        complexity_class = \"O(n) - Linear\"\n",
    "    elif power_slope < 1.8:\n",
    "        complexity_class = f\"O(n^{power_slope:.1f}) - Sub-quadratic\"\n",
    "    elif power_slope < 2.2:\n",
    "        complexity_class = \"O(n²) - Quadratic\"\n",
    "    else:\n",
    "        complexity_class = f\"O(n^{power_slope:.1f}) - Super-quadratic\"\n",
    "\n",
    "    print(f\"Estimated complexity: {complexity_class}\")\n",
    "\n",
    "    return {\n",
    "        'linear_r2': linear_r2,\n",
    "        'quad_r2': quad_r2,\n",
    "        'log_r2': log_r2,\n",
    "        'power_slope': power_slope,\n",
    "        'power_r2': power_r**2,\n",
    "        'complexity_class': complexity_class,\n",
    "        'linear_coef': linear_coef\n",
    "    }\n",
    "\n",
    "# Core VABE operations analysis\n",
    "operations = {\n",
    "    'KeyGen': 'KeyGenTime(s)',\n",
    "    'VerifyKey': 'VerifyKeyTime(s)',\n",
    "    'Encrypt': 'EncryptTime(s)',\n",
    "    'VerifyCiphertext': 'VerifyCiphertextTime(s)',\n",
    "    'Decrypt(Match)': 'DecryptMatchingTime(s)',\n",
    "    'Decrypt(NoMatch)': 'DecryptNonMatchingTime(s)'\n",
    "}\n",
    "\n",
    "print(\"\\nComplexity Analysis for Each Operation:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "complexity_results = {}\n",
    "for op_name, col_name in operations.items():\n",
    "    complexity_results[op_name] = analyze_complexity(df['Size'].values, df[col_name].values, op_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6019c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. VABE Verification Efficiency Analysis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VABE VERIFICATION EFFICIENCY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Key Generation vs Key Verification\n",
    "df['VerifyKey_Overhead'] = df['VerifyKeyTime(s)'] / df['KeyGenTime(s)']\n",
    "df['VerifyKey_Overhead_Ratio'] = df['VerifyKeyTime(ms)'] / df['KeyGenTime(ms)']\n",
    "\n",
    "print(f\"\\nKey Verification Analysis:\")\n",
    "print(f\"Average verification overhead: {df['VerifyKey_Overhead'].mean():.3f}x of KeyGen time\")\n",
    "print(f\"Overhead range: {df['VerifyKey_Overhead'].min():.3f}x - {df['VerifyKey_Overhead'].max():.3f}x\")\n",
    "print(f\"Overhead std deviation: {df['VerifyKey_Overhead'].std():.3f}\")\n",
    "\n",
    "# Encryption vs Ciphertext Verification\n",
    "df['VerifyCiphertext_Overhead'] = df['VerifyCiphertextTime(s)'] / df['EncryptTime(s)']\n",
    "df['VerifyCiphertext_Overhead_Ratio'] = df['VerifyCiphertextTime(ms)'] / df['EncryptTime(ms)']\n",
    "\n",
    "print(f\"\\nCiphertext Verification Analysis:\")\n",
    "print(f\"Average verification overhead: {df['VerifyCiphertext_Overhead'].mean():.3f}x of Encrypt time\")\n",
    "print(f\"Overhead range: {df['VerifyCiphertext_Overhead'].min():.3f}x - {df['VerifyCiphertext_Overhead'].max():.3f}x\")\n",
    "print(f\"Overhead std deviation: {df['VerifyCiphertext_Overhead'].std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Security vs Efficiency Trade-off Analysis\n",
    "print(f\"\\nSecurity-Efficiency Trade-off:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Calculate total original scheme time vs VABE scheme time\n",
    "df['Original_Total'] = df['KeyGenTime(s)'] + df['EncryptTime(s)'] + df['DecryptMatchingTime(s)']\n",
    "df['VABE_Total'] = df['KeyGenTime(s)'] + df['VerifyKeyTime(s)'] + df['EncryptTime(s)'] + df['VerifyCiphertextTime(s)'] + df['DecryptMatchingTime(s)']\n",
    "df['VABE_Overhead'] = df['VABE_Total'] / df['Original_Total']\n",
    "\n",
    "print(f\"VABE total overhead: {df['VABE_Overhead'].mean():.3f}x of original scheme\")\n",
    "print(f\"Security overhead range: {df['VABE_Overhead'].min():.3f}x - {df['VABE_Overhead'].max():.3f}x\")\n",
    "\n",
    "# Verification time as percentage of total operation\n",
    "df['Verification_Percentage'] = (df['VerifyKeyTime(s)'] + df['VerifyCiphertextTime(s)']) / df['VABE_Total'] * 100\n",
    "\n",
    "print(f\"Verification time percentage of total: {df['Verification_Percentage'].mean():.1f}% ± {df['Verification_Percentage'].std():.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d41806",
   "metadata": {},
   "source": [
    "### Visualize Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48df7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION SECTION\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING PUBLICATION-QUALITY VISUALIZATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Figure 1: VABE Core Operations Complexity Analysis\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# KeyGen vs VerifyKey comparison\n",
    "ax1.loglog(df['Size'], df['KeyGenTime(s)'], 'b-o', linewidth=3, markersize=8, label='KeyGen', alpha=0.8)\n",
    "ax1.loglog(df['Size'], df['VerifyKeyTime(s)'], 'r-s', linewidth=3, markersize=8, label='VerifyKey', alpha=0.8)\n",
    "\n",
    "# Add complexity trend lines\n",
    "sizes_smooth = np.logspace(np.log10(df['Size'].min()), np.log10(df['Size'].max()), 100)\n",
    "keygen_slope = complexity_results['KeyGen']['power_slope']\n",
    "verifykey_slope = complexity_results['VerifyKey']['power_slope']\n",
    "\n",
    "keygen_trend = df['KeyGenTime(s)'].iloc[0] * (sizes_smooth / df['Size'].iloc[0])**keygen_slope\n",
    "verifykey_trend = df['VerifyKeyTime(s)'].iloc[0] * (sizes_smooth / df['Size'].iloc[0])**verifykey_slope\n",
    "\n",
    "ax1.loglog(sizes_smooth, keygen_trend, 'b--', alpha=0.6, label=f'KeyGen trend O(n^{keygen_slope:.2f})')\n",
    "ax1.loglog(sizes_smooth, verifykey_trend, 'r--', alpha=0.6, label=f'VerifyKey trend O(n^{verifykey_slope:.2f})')\n",
    "\n",
    "ax1.set_xlabel('Policy Complexity (Number of Attributes)')\n",
    "ax1.set_ylabel('Time (seconds)')\n",
    "ax1.set_title('Key Generation vs Key Verification')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Encrypt vs VerifyCiphertext comparison\n",
    "ax2.loglog(df['Size'], df['EncryptTime(s)'], 'g-o', linewidth=3, markersize=8, label='Encrypt', alpha=0.8)\n",
    "ax2.loglog(df['Size'], df['VerifyCiphertextTime(s)'], 'm-s', linewidth=3, markersize=8, label='VerifyCiphertext', alpha=0.8)\n",
    "\n",
    "encrypt_slope = complexity_results['Encrypt']['power_slope']\n",
    "verifyciphertext_slope = complexity_results['VerifyCiphertext']['power_slope']\n",
    "\n",
    "encrypt_trend = df['EncryptTime(s)'].iloc[0] * (sizes_smooth / df['Size'].iloc[0])**encrypt_slope\n",
    "verifyciphertext_trend = df['VerifyCiphertextTime(s)'].iloc[0] * (sizes_smooth / df['Size'].iloc[0])**verifyciphertext_slope\n",
    "\n",
    "ax2.loglog(sizes_smooth, encrypt_trend, 'g--', alpha=0.6, label=f'Encrypt trend O(n^{encrypt_slope:.2f})')\n",
    "ax2.loglog(sizes_smooth, verifyciphertext_trend, 'm--', alpha=0.6, label=f'VerifyCiphertext trend O(n^{verifyciphertext_slope:.2f})')\n",
    "\n",
    "ax2.set_xlabel('Policy Complexity (Number of Attributes)')\n",
    "ax2.set_ylabel('Time (seconds)')\n",
    "ax2.set_title('Encryption vs Ciphertext Verification')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Verification overhead analysis\n",
    "ax3.semilogx(df['Size'], df['VerifyKey_Overhead'], 'r-o', linewidth=3, markersize=8, label='Key Verification Overhead', alpha=0.8)\n",
    "ax3.semilogx(df['Size'], df['VerifyCiphertext_Overhead'], 'm-s', linewidth=3, markersize=8, label='Ciphertext Verification Overhead', alpha=0.8)\n",
    "\n",
    "ax3.axhline(y=1, color='black', linestyle='--', alpha=0.5, label='Original Operation Time')\n",
    "ax3.set_xlabel('Policy Complexity (Number of Attributes)')\n",
    "ax3.set_ylabel('Verification Overhead (×)')\n",
    "ax3.set_title('VABE Verification Overhead Analysis')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Overall scheme comparison\n",
    "ax4.loglog(df['Size'], df['Original_Total'], 'k-o', linewidth=3, markersize=8, label='Original ABE', alpha=0.8)\n",
    "ax4.loglog(df['Size'], df['VABE_Total'], 'orange', linestyle='-', marker='s', linewidth=3, markersize=8, label='VABE (with verification)', alpha=0.8)\n",
    "ax4.loglog(df['Size'], df['VerifyKeyTime(s)'] + df['VerifyCiphertextTime(s)'], 'red', linestyle=':', marker='^', linewidth=3, markersize=8, label='Verification Only', alpha=0.8)\n",
    "\n",
    "ax4.set_xlabel('Policy Complexity (Number of Attributes)')\n",
    "ax4.set_ylabel('Total Time (seconds)')\n",
    "ax4.set_title('Original ABE vs VABE Scheme Comparison')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vabe_core_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: VABE Efficiency and Scalability Analysis\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Time per attribute analysis\n",
    "df['KeyGen_per_attr'] = df['KeyGenTime(ms)'] / df['Size']\n",
    "df['VerifyKey_per_attr'] = df['VerifyKeyTime(ms)'] / df['Size']\n",
    "df['Encrypt_per_attr'] = df['EncryptTime(ms)'] / df['Size']\n",
    "df['VerifyCiphertext_per_attr'] = df['VerifyCiphertextTime(ms)'] / df['Size']\n",
    "\n",
    "ax1.semilogx(df['Size'], df['KeyGen_per_attr'], 'b-o', linewidth=2, label='KeyGen/attr')\n",
    "ax1.semilogx(df['Size'], df['VerifyKey_per_attr'], 'r-s', linewidth=2, label='VerifyKey/attr')\n",
    "ax1.set_xlabel('Policy Complexity (Number of Attributes)')\n",
    "ax1.set_ylabel('Time per Attribute (ms)')\n",
    "ax1.set_title('Key Operations: Time per Attribute')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.semilogx(df['Size'], df['Encrypt_per_attr'], 'g-o', linewidth=2, label='Encrypt/attr')\n",
    "ax2.semilogx(df['Size'], df['VerifyCiphertext_per_attr'], 'm-s', linewidth=2, label='VerifyCiphertext/attr')\n",
    "ax2.set_xlabel('Policy Complexity (Number of Attributes)')\n",
    "ax2.set_ylabel('Time per Attribute (ms)')\n",
    "ax2.set_title('Encryption Operations: Time per Attribute')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Security overhead vs policy complexity\n",
    "ax3.semilogx(df['Size'], df['VABE_Overhead'], 'orange', linestyle='-', marker='o', linewidth=3, markersize=8, alpha=0.8)\n",
    "ax3.axhline(y=1, color='black', linestyle='--', alpha=0.5, label='No overhead baseline')\n",
    "ax3.fill_between(df['Size'], 1, df['VABE_Overhead'], alpha=0.2, color='orange', label='Security overhead')\n",
    "\n",
    "ax3.set_xlabel('Policy Complexity (Number of Attributes)')\n",
    "ax3.set_ylabel('Total Scheme Overhead (×)')\n",
    "ax3.set_title('VABE Security Overhead vs Policy Complexity')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Verification efficiency comparison\n",
    "verification_total = df['VerifyKeyTime(s)'] + df['VerifyCiphertextTime(s)']\n",
    "original_total = df['KeyGenTime(s)'] + df['EncryptTime(s)']\n",
    "\n",
    "ax4.loglog(original_total, verification_total, 'ro-', linewidth=2, markersize=8, alpha=0.8)\n",
    "ax4.plot([original_total.min(), original_total.max()],\n",
    "         [original_total.min(), original_total.max()], 'k--', alpha=0.5, label='Equal time line')\n",
    "\n",
    "ax4.set_xlabel('Original Operations Time (seconds)')\n",
    "ax4.set_ylabel('Verification Operations Time (seconds)')\n",
    "ax4.set_title('Verification Efficiency Trade-off')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations for specific policy sizes\n",
    "for i, size in enumerate(df['Size']):\n",
    "    if size in [10, 100, 1000, 10000, 100000]:\n",
    "        ax4.annotate(f'{size} attrs',\n",
    "                    (original_total.iloc[i], verification_total.iloc[i]),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vabe_efficiency_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Comparative Performance Summary\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# All operations comparison\n",
    "operations_data = {\n",
    "    'KeyGen': df['KeyGenTime(s)'],\n",
    "    'VerifyKey': df['VerifyKeyTime(s)'],\n",
    "    'Encrypt': df['EncryptTime(s)'],\n",
    "    'VerifyCiphertext': df['VerifyCiphertextTime(s)'],\n",
    "    'Decrypt': df['DecryptMatchingTime(s)']\n",
    "}\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "for i, (op, data) in enumerate(operations_data.items()):\n",
    "    ax1.loglog(df['Size'], data, 'o-', linewidth=2, markersize=6,\n",
    "               label=op, color=colors[i], alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Policy Complexity (Number of Attributes)')\n",
    "ax1.set_ylabel('Time (seconds)')\n",
    "ax1.set_title('VABE All Operations Performance')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Normalized performance (relative to smallest size)\n",
    "normalized_data = {}\n",
    "for op, data in operations_data.items():\n",
    "    normalized_data[op] = data / data.iloc[0]\n",
    "\n",
    "for i, (op, data) in enumerate(normalized_data.items()):\n",
    "    ax2.loglog(df['Size'], data, 'o-', linewidth=2, markersize=6,\n",
    "               label=op, color=colors[i], alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Policy Complexity (Number of Attributes)')\n",
    "ax2.set_ylabel('Normalized Time (relative to 10 attributes)')\n",
    "ax2.set_title('Relative Performance Scaling')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Complexity comparison bar chart\n",
    "complexity_data = {\n",
    "    'KeyGen': complexity_results['KeyGen']['power_slope'],\n",
    "    'VerifyKey': complexity_results['VerifyKey']['power_slope'],\n",
    "    'Encrypt': complexity_results['Encrypt']['power_slope'],\n",
    "    'VerifyCiphertext': complexity_results['VerifyCiphertext']['power_slope'],\n",
    "    'Decrypt': complexity_results['Decrypt(Match)']['power_slope']\n",
    "}\n",
    "\n",
    "operations_list = list(complexity_data.keys())\n",
    "slopes = list(complexity_data.values())\n",
    "bars = ax3.bar(operations_list, slopes, color=colors, alpha=0.7)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, slope in zip(bars, slopes):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "             f'{slope:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax3.set_ylabel('Complexity Exponent')\n",
    "ax3.set_title('Algorithmic Complexity Comparison (O(n^exponent))')\n",
    "ax3.set_ylim(0, max(slopes) + 0.3)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "plt.setp(ax3.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Performance efficiency summary\n",
    "categories = ['Key\\nOperations', 'Encryption\\nOperations', 'Total\\nScheme']\n",
    "original_times = [\n",
    "    df['KeyGenTime(s)'].mean(),\n",
    "    df['EncryptTime(s)'].mean(),\n",
    "    df['Original_Total'].mean()\n",
    "]\n",
    "vabe_times = [\n",
    "    (df['KeyGenTime(s)'] + df['VerifyKeyTime(s)']).mean(),\n",
    "    (df['EncryptTime(s)'] + df['VerifyCiphertextTime(s)']).mean(),\n",
    "    df['VABE_Total'].mean()\n",
    "]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax4.bar(x - width/2, original_times, width, label='Original ABE', alpha=0.8, color='lightblue')\n",
    "bars2 = ax4.bar(x + width/2, vabe_times, width, label='VABE', alpha=0.8, color='lightcoral')\n",
    "\n",
    "# Add overhead percentages\n",
    "for i, (orig, vabe) in enumerate(zip(original_times, vabe_times)):\n",
    "    overhead = ((vabe - orig) / orig) * 100\n",
    "    ax4.text(i, max(orig, vabe) + max(vabe_times) * 0.05,\n",
    "             f'+{overhead:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax4.set_ylabel('Average Time (seconds)')\n",
    "ax4.set_title('VABE Security Overhead Summary')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(categories)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vabe_performance_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc09dd28",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Final Benchmark Report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VABE BENCHMARK REPORT FOR CRYPTOGRAPHY PAPER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "report = f\"\"\"\n",
    "VABE (Verifiable Attribute-Based Encryption) Performance Analysis\n",
    "================================================================\n",
    "\n",
    "I. ALGORITHM COMPLEXITY ANALYSIS\n",
    "--------------------------------\n",
    "Key Generation:          {complexity_results['KeyGen']['complexity_class']} (R² = {complexity_results['KeyGen']['power_r2']:.3f})\n",
    "Key Verification:        {complexity_results['VerifyKey']['complexity_class']} (R² = {complexity_results['VerifyKey']['power_r2']:.3f})\n",
    "Encryption:              {complexity_results['Encrypt']['complexity_class']} (R² = {complexity_results['Encrypt']['power_r2']:.3f})\n",
    "Ciphertext Verification: {complexity_results['VerifyCiphertext']['complexity_class']} (R² = {complexity_results['VerifyCiphertext']['power_r2']:.3f})\n",
    "\n",
    "II. VABE VERIFICATION EFFICIENCY\n",
    "--------------------------------\n",
    "Key Verification Overhead:        {df['VerifyKey_Overhead'].mean():.2f}× ± {df['VerifyKey_Overhead'].std():.2f}× of KeyGen\n",
    "Ciphertext Verification Overhead: {df['VerifyCiphertext_Overhead'].mean():.2f}× ± {df['VerifyCiphertext_Overhead'].std():.2f}× of Encrypt\n",
    "\n",
    "III. SECURITY VS EFFICIENCY TRADE-OFF\n",
    "-------------------------------------\n",
    "VABE Total Overhead:      {df['VABE_Overhead'].mean():.2f}× of original ABE scheme\n",
    "Verification Percentage:  {df['Verification_Percentage'].mean():.1f}% of total VABE execution time\n",
    "Security Cost Range:      {df['VABE_Overhead'].min():.2f}× to {df['VABE_Overhead'].max():.2f}× across policy complexities\n",
    "\n",
    "IV. SCALABILITY ANALYSIS\n",
    "------------------------\n",
    "Policy Complexity Range: {df['Size'].min()} to {df['Size'].max():,} attributes\n",
    "Best Performance Point:  ~{df.loc[df['VABE_Overhead'].idxmin(), 'Size']:,} attributes (lowest overhead: {df['VABE_Overhead'].min():.2f}×)\n",
    "Worst Performance Point: ~{df.loc[df['VABE_Overhead'].idxmax(), 'Size']:,} attributes (highest overhead: {df['VABE_Overhead'].max():.2f}×)\n",
    "\n",
    "V. KEY FINDINGS FOR CRYPTOGRAPHY PAPER\n",
    "--------------------------------------\n",
    "1. EFFICIENCY: VABE adds {((df['VABE_Overhead'].mean() - 1) * 100):.1f}% computational overhead on average\n",
    "2. SCALABILITY: Both verification functions scale similarly to their original counterparts\n",
    "3. SECURITY: Verification provides cryptographic guarantees with manageable performance cost\n",
    "4. PRACTICALITY: Overhead remains reasonable even for complex policies (>100k attributes)\n",
    "\n",
    "VI. PERFORMANCE RECOMMENDATIONS\n",
    "------------------------------\n",
    "- Optimal range: {df.loc[df['VABE_Overhead'] < df['VABE_Overhead'].quantile(0.25), 'Size'].max():,} attributes for minimal overhead\n",
    "- Acceptable range: Up to {df.loc[df['VABE_Overhead'] < df['VABE_Overhead'].quantile(0.75), 'Size'].max():,} attributes for practical deployment\n",
    "- Verification-to-computation ratio: {((df['VerifyKeyTime(s)'] + df['VerifyCiphertextTime(s)']) / (df['KeyGenTime(s)'] + df['EncryptTime(s)'])).mean():.2f}:1\n",
    "\n",
    "CONCLUSION: VABE provides verifiable attribute-based encryption with {df['VABE_Overhead'].mean():.1f}× overhead,\n",
    "maintaining practical performance while adding crucial security verification capabilities.\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save detailed results for paper\n",
    "summary_results = pd.DataFrame({\n",
    "    'Policy_Size': df['Size'],\n",
    "    'KeyGen_ms': df['KeyGenTime(ms)'],\n",
    "    'VerifyKey_ms': df['VerifyKeyTime(ms)'],\n",
    "    'Encrypt_ms': df['EncryptTime(ms)'],\n",
    "    'VerifyCiphertext_ms': df['VerifyCiphertextTime(ms)'],\n",
    "    'KeyVerify_Overhead': df['VerifyKey_Overhead'],\n",
    "    'CiphertextVerify_Overhead': df['VerifyCiphertext_Overhead'],\n",
    "    'Total_VABE_Overhead': df['VABE_Overhead'],\n",
    "    'Verification_Percentage': df['Verification_Percentage']\n",
    "})\n",
    "\n",
    "summary_results.to_csv('vabe_paper_results.csv', index=False)\n",
    "\n",
    "# Create complexity summary table\n",
    "complexity_summary = pd.DataFrame({\n",
    "    'Operation': ['KeyGen', 'VerifyKey', 'Encrypt', 'VerifyCiphertext'],\n",
    "    'Complexity_Class': [\n",
    "        complexity_results['KeyGen']['complexity_class'],\n",
    "        complexity_results['VerifyKey']['complexity_class'],\n",
    "        complexity_results['Encrypt']['complexity_class'],\n",
    "        complexity_results['VerifyCiphertext']['complexity_class']\n",
    "    ],\n",
    "    'Power_Exponent': [\n",
    "        complexity_results['KeyGen']['power_slope'],\n",
    "        complexity_results['VerifyKey']['power_slope'],\n",
    "        complexity_results['Encrypt']['power_slope'],\n",
    "        complexity_results['VerifyCiphertext']['power_slope']\n",
    "    ],\n",
    "    'R_Squared': [\n",
    "        complexity_results['KeyGen']['power_r2'],\n",
    "        complexity_results['VerifyKey']['power_r2'],\n",
    "        complexity_results['Encrypt']['power_r2'],\n",
    "        complexity_results['VerifyCiphertext']['power_r2']\n",
    "    ]\n",
    "})\n",
    "\n",
    "complexity_summary.to_csv('vabe_complexity_analysis.csv', index=False)\n",
    "\n",
    "print(f\"\\nFiles generated for paper:\")\n",
    "print(f\"1. vabe_paper_results.csv - Detailed benchmark data\")\n",
    "print(f\"2. vabe_complexity_analysis.csv - Algorithm complexity summary\")\n",
    "print(f\"3. vabe_core_analysis.png - Core VABE operations comparison\")\n",
    "print(f\"4. vabe_efficiency_analysis.png - Efficiency and scalability analysis\")\n",
    "print(f\"5. vabe_performance_summary.png - Performance summary for paper\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE - READY FOR CRYPTOGRAPHY PAPER\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
